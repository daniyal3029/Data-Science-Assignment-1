# ğŸš• NYC Congestion Pricing Audit 2025

**A data engineering project analyzing the impact of NYC's Congestion Relief Zone Toll using TLC taxi data.**

---

## ğŸ“‹ Project Overview

On January 5, 2025, New York City implemented a congestion pricing toll for vehicles entering Manhattan south of 60th Street. This project audits the policy's effectiveness by analyzing:

- **Trip volume changes** (before vs. after implementation)
- **Revenue compliance** (toll collection rates)
- **Ghost trip detection** (fraudulent/erroneous records)
- **Behavioral shifts** (Yellow vs. Green taxi patterns)
- **Weather impact** (precipitation elasticity)

---

## ğŸ¯ Assignment Deliverables

- [x] `pipeline.py` - Automated, reproducible data pipeline
- [ ] `audit_report.pdf` - Executive summary with policy recommendations
- [ ] Streamlit Dashboard (4 tabs: Map | Flow | Economics | Weather)
- [ ] Medium blog post
- [ ] LinkedIn professional post

---

## ğŸ—ï¸ Project Structure

```
DataScience_Assignment1/
â”œâ”€â”€ data/                   # Data layer (gitignored)
â”‚   â”œâ”€â”€ raw/                # Original TLC parquet files
â”‚   â”œâ”€â”€ processed/          # Cleaned, unified data
â”‚   â””â”€â”€ aggregated/         # Small aggregated files for viz
â”œâ”€â”€ src/                    # Modular Python code
â”‚   â”œâ”€â”€ ingestion.py        # PHASE 1: Download automation
â”‚   â”œâ”€â”€ schema.py           # PHASE 2: Schema unification
â”‚   â”œâ”€â”€ cleaning.py         # PHASE 3: Ghost trip detection
â”‚   â”œâ”€â”€ imputation.py       # PHASE 4: Missing data handling
â”‚   â”œâ”€â”€ zones.py            # PHASE 5: Congestion zone logic
â”‚   â”œâ”€â”€ analysis.py         # PHASE 6-7: Compliance & comparison
â”‚   â”œâ”€â”€ visualization.py    # PHASE 8: Chart generation
â”‚   â””â”€â”€ weather.py          # PHASE 9: Weather integration
â”œâ”€â”€ dashboard/              # Streamlit app
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ outputs/                # Reports, figures, logs
â””â”€â”€ pipeline.py             # Main orchestrator
```

---

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Run automated setup
setup_project.bat

# Activate virtual environment
venv\Scripts\activate

# Verify installation
python -c "import duckdb; print('âœ“ DuckDB ready')"
```

### 2. Run Pipeline

```bash
# Full pipeline (all phases)
python pipeline.py

# Individual phases
python pipeline.py --phase ingestion
python pipeline.py --phase cleaning
```

### 3. Launch Dashboard

```bash
streamlit run dashboard/app.py
```

---

## ğŸ› ï¸ Technology Stack

| Component | Tool | Why? |
|-----------|------|------|
| **Big Data Engine** | DuckDB | Out-of-core processing, SQL-based, parquet-native |
| **Geospatial** | GeoPandas | Shapefile handling, zone filtering |
| **Visualization** | Plotly + Folium | Interactive charts and maps |
| **Dashboard** | Streamlit | Rapid prototyping, easy deployment |
| **Weather Data** | Meteostat | Historical precipitation data |

---

## ğŸ“Š Key Constraints

âœ… **DO:**
- Use DuckDB/Spark/Polars for all data processing
- Aggregate before plotting
- Auto-handle missing December 2025 data
- Detect and log ghost trips
- Build real, actionable insights

âŒ **DON'T:**
- Load full datasets into pandas
- Skip data validation
- Use toy examples
- Violate "Big Data only" rule

---

## ğŸ“ˆ Development Phases

- [x] **PHASE 0**: Project setup
- [ ] **PHASE 1**: Automated data ingestion
- [ ] **PHASE 2**: Schema unification
- [ ] **PHASE 3**: Ghost trip detection
- [ ] **PHASE 4**: Missing data imputation
- [ ] **PHASE 5**: Congestion zone filtering
- [ ] **PHASE 6**: Leakage & compliance analysis
- [ ] **PHASE 7**: Yellow vs. Green comparison
- [ ] **PHASE 8**: Visual audit
- [ ] **PHASE 9**: Weather elasticity
- [ ] **PHASE 10**: Streamlit dashboard
- [ ] **PHASE 11**: Audit report
- [ ] **PHASE 12**: Medium + LinkedIn posts

---

## ğŸ‘¨â€ğŸ’» Author

**Daniyal Haider**  
Final-Year Software Engineering Student  
Data Science Assignment 1 - 2025

---

## ğŸ“ License

Academic project - Not for commercial use
